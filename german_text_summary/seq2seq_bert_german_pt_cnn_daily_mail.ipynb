{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Text Summary with the tranlated CNN Daily Mail Dataset\n",
    "This time We will try out a Seq2Seq Bert Model which is pretrained on German data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "import time\n",
    "\n",
    "from transformers import BertTokenizer, EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "\n",
    "SHUFFEL_SIZE = 1024\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "learning_rate = 3e-5\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "log_interval = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-german-cased\", \"bert-base-german-cased\").to(device)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "\n",
    "\n",
    "# model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"distilbert-base-german-cased\", \"distilbert-base-german-cased\").to(device)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"distilbert-base-german-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLS token will work as BOS token\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "\n",
    "# SEP token will work as EOS token\n",
    "tokenizer.eos_token = tokenizer.sep_token\n",
    "\n",
    "# set decoding params\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.max_length = 142\n",
    "model.config.min_length = 56\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.early_stopping = True\n",
    "model.length_penalty = 2.0\n",
    "model.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translated_ds(name):\n",
    "    article_path = \"../data/%s/articles_german\" % name\n",
    "    highlights_path = \"../data/%s/highlights_german\" % name\n",
    "\n",
    "    articles = [x.rstrip() for x in open(article_path).readlines()]\n",
    "    highlights = [x.rstrip() for x in open(highlights_path).readlines()]\n",
    "    \n",
    "    assert len(articles) == len(highlights)\n",
    "    return articles, highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = get_translated_ds(\"train\")\n",
    "test_x, test_y = get_translated_ds(\"test\")\n",
    "val_x, val_y = get_translated_ds(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, articles, highlights):\n",
    "        self.x = articles\n",
    "        self.y = highlights\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = tokenizer.encode_plus(self.transfrom(self.x[index]), max_length=512, return_tensors=\"pt\", pad_to_max_length=True)\n",
    "        y = tokenizer.encode(self.transfrom(self.y[index]), max_length=150, return_tensors=\"pt\", pad_to_max_length=True)\n",
    "        return x['input_ids'].view(-1), x['attention_mask'].view(-1), y.view(-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def transfrom(x):\n",
    "        x = re.sub(\"'(.*)'\", r\"\\1\", x)\n",
    "        return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 512]), torch.Size([6, 512]), torch.Size([6, 150]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = MyDataset(train_x, train_y) \n",
    "val_ds = MyDataset(val_x, val_y)\n",
    "test_ds = MyDataset(test_x, test_y)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "x, x_mask, y = next(iter(val_loader))\n",
    "x.shape, x_mask.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = tokenizer.pad_token_id\n",
    "def step(inputs_ids, attention_mask, y):\n",
    "    y_ids = y[:, :-1].contiguous()\n",
    "    lm_labels = y[:, 1:].clone()\n",
    "    lm_labels[y[:, 1:] == pad_token_id] = -100\n",
    "    output = model(inputs_ids, attention_mask=attention_mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
    "    return output[0] # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | [  199/47853] | ms/batch 219.17 | loss  6.04 | val loss  6.29\n",
      "| epoch   0 | [  399/47853] | ms/batch 220.98 | loss  6.04 | val loss  6.28\n",
      "| epoch   0 | [  599/47853] | ms/batch 219.11 | loss  6.57 | val loss  6.28\n",
      "| epoch   0 | [  799/47853] | ms/batch 220.19 | loss  6.39 | val loss  6.32\n",
      "| epoch   0 | [  999/47853] | ms/batch 220.33 | loss  6.11 | val loss  6.31\n",
      "| epoch   0 | [ 1199/47853] | ms/batch 220.84 | loss  6.27 | val loss  6.29\n",
      "| epoch   0 | [ 1399/47853] | ms/batch 218.24 | loss  6.23 | val loss  6.29\n",
      "| epoch   0 | [ 1599/47853] | ms/batch 220.21 | loss  5.80 | val loss  6.35\n",
      "| epoch   0 | [ 1799/47853] | ms/batch 221.47 | loss  6.13 | val loss  6.31\n",
      "| epoch   0 | [ 1999/47853] | ms/batch 220.87 | loss  6.46 | val loss  6.36\n",
      "| epoch   0 | [ 2199/47853] | ms/batch 220.49 | loss  6.16 | val loss  6.38\n",
      "| epoch   0 | [ 2399/47853] | ms/batch 221.15 | loss  6.15 | val loss  6.42\n",
      "| epoch   0 | [ 2599/47853] | ms/batch 220.86 | loss  6.27 | val loss  6.37\n",
      "| epoch   0 | [ 2799/47853] | ms/batch 222.42 | loss  6.19 | val loss  6.33\n",
      "| epoch   0 | [ 2999/47853] | ms/batch 221.39 | loss  6.13 | val loss  6.34\n",
      "| epoch   0 | [ 3199/47853] | ms/batch 221.00 | loss  6.30 | val loss  6.34\n",
      "| epoch   0 | [ 3399/47853] | ms/batch 221.47 | loss  6.09 | val loss  6.41\n",
      "| epoch   0 | [ 3599/47853] | ms/batch 221.31 | loss  6.08 | val loss  6.38\n",
      "| epoch   0 | [ 3799/47853] | ms/batch 220.62 | loss  6.03 | val loss  6.36\n",
      "| epoch   0 | [ 3999/47853] | ms/batch 222.27 | loss  5.64 | val loss  6.36\n",
      "| epoch   0 | [ 4199/47853] | ms/batch 220.61 | loss  6.21 | val loss  6.39\n",
      "| epoch   0 | [ 4399/47853] | ms/batch 220.13 | loss  6.12 | val loss  6.34\n",
      "| epoch   0 | [ 4599/47853] | ms/batch 220.94 | loss  5.64 | val loss  6.37\n",
      "| epoch   0 | [ 4799/47853] | ms/batch 219.98 | loss  5.97 | val loss  6.37\n",
      "| epoch   0 | [ 4999/47853] | ms/batch 221.11 | loss  6.11 | val loss  6.40\n",
      "| epoch   0 | [ 5199/47853] | ms/batch 220.04 | loss  5.87 | val loss  6.37\n",
      "| epoch   0 | [ 5399/47853] | ms/batch 222.09 | loss  5.84 | val loss  6.39\n",
      "| epoch   0 | [ 5599/47853] | ms/batch 221.56 | loss  6.05 | val loss  6.36\n",
      "| epoch   0 | [ 5799/47853] | ms/batch 220.93 | loss  6.04 | val loss  6.37\n",
      "| epoch   0 | [ 5999/47853] | ms/batch 220.55 | loss  6.20 | val loss  6.37\n",
      "| epoch   0 | [ 6199/47853] | ms/batch 222.54 | loss  6.16 | val loss  6.39\n",
      "| epoch   0 | [ 6399/47853] | ms/batch 221.54 | loss  6.03 | val loss  6.37\n",
      "| epoch   0 | [ 6599/47853] | ms/batch 220.87 | loss  6.05 | val loss  6.40\n",
      "| epoch   0 | [ 6799/47853] | ms/batch 221.73 | loss  6.37 | val loss  6.39\n",
      "| epoch   0 | [ 6999/47853] | ms/batch 221.77 | loss  6.63 | val loss  6.37\n",
      "| epoch   0 | [ 7199/47853] | ms/batch 220.36 | loss  6.21 | val loss  6.35\n",
      "| epoch   0 | [ 7399/47853] | ms/batch 220.43 | loss  6.28 | val loss  6.35\n",
      "| epoch   0 | [ 7599/47853] | ms/batch 222.02 | loss  6.24 | val loss  6.38\n",
      "| epoch   0 | [ 7799/47853] | ms/batch 220.46 | loss  6.38 | val loss  6.36\n",
      "| epoch   0 | [ 7999/47853] | ms/batch 219.60 | loss  5.80 | val loss  6.37\n",
      "| epoch   0 | [ 8199/47853] | ms/batch 220.65 | loss  5.88 | val loss  6.34\n",
      "| epoch   0 | [ 8399/47853] | ms/batch 219.73 | loss  5.97 | val loss  6.36\n",
      "| epoch   0 | [ 8599/47853] | ms/batch 219.59 | loss  6.28 | val loss  6.34\n",
      "| epoch   0 | [ 8799/47853] | ms/batch 222.41 | loss  5.81 | val loss  6.37\n",
      "| epoch   0 | [ 8999/47853] | ms/batch 221.21 | loss  6.45 | val loss  6.36\n",
      "| epoch   0 | [ 9199/47853] | ms/batch 219.65 | loss  6.43 | val loss  6.35\n",
      "| epoch   0 | [ 9399/47853] | ms/batch 221.69 | loss  6.32 | val loss  6.37\n",
      "| epoch   0 | [ 9599/47853] | ms/batch 221.53 | loss  6.33 | val loss  6.40\n",
      "| epoch   0 | [ 9799/47853] | ms/batch 222.03 | loss  6.52 | val loss  6.39\n",
      "| epoch   0 | [ 9999/47853] | ms/batch 221.26 | loss  6.35 | val loss  6.38\n",
      "| epoch   0 | [10199/47853] | ms/batch 220.11 | loss  6.42 | val loss  6.35\n",
      "| epoch   0 | [10399/47853] | ms/batch 221.60 | loss  6.10 | val loss  6.38\n",
      "| epoch   0 | [10599/47853] | ms/batch 222.11 | loss  6.19 | val loss  6.36\n",
      "| epoch   0 | [10799/47853] | ms/batch 221.72 | loss  6.42 | val loss  6.39\n",
      "| epoch   0 | [10999/47853] | ms/batch 220.11 | loss  5.90 | val loss  6.39\n",
      "| epoch   0 | [11199/47853] | ms/batch 222.57 | loss  6.37 | val loss  6.38\n",
      "| epoch   0 | [11399/47853] | ms/batch 221.74 | loss  6.29 | val loss  6.35\n",
      "| epoch   0 | [11599/47853] | ms/batch 221.39 | loss  6.06 | val loss  6.38\n",
      "| epoch   0 | [11799/47853] | ms/batch 220.93 | loss  6.52 | val loss  6.39\n",
      "| epoch   0 | [11999/47853] | ms/batch 221.84 | loss  6.41 | val loss  6.37\n",
      "| epoch   0 | [12199/47853] | ms/batch 221.81 | loss  6.24 | val loss  6.39\n",
      "| epoch   0 | [12399/47853] | ms/batch 221.70 | loss  6.17 | val loss  6.39\n",
      "| epoch   0 | [12599/47853] | ms/batch 221.15 | loss  6.08 | val loss  6.35\n",
      "| epoch   0 | [12799/47853] | ms/batch 220.70 | loss  6.14 | val loss  6.41\n",
      "| epoch   0 | [12999/47853] | ms/batch 220.03 | loss  6.08 | val loss  6.38\n",
      "| epoch   0 | [13199/47853] | ms/batch 223.22 | loss  6.07 | val loss  6.37\n",
      "| epoch   0 | [13399/47853] | ms/batch 221.94 | loss  6.17 | val loss  6.39\n",
      "| epoch   0 | [13599/47853] | ms/batch 220.76 | loss  6.13 | val loss  6.39\n",
      "| epoch   0 | [13799/47853] | ms/batch 220.30 | loss  6.10 | val loss  6.44\n",
      "| epoch   0 | [13999/47853] | ms/batch 220.07 | loss  6.23 | val loss  6.43\n",
      "| epoch   0 | [14199/47853] | ms/batch 220.90 | loss  5.89 | val loss  6.40\n",
      "| epoch   0 | [14399/47853] | ms/batch 221.39 | loss  6.27 | val loss  6.40\n",
      "| epoch   0 | [14599/47853] | ms/batch 221.52 | loss  6.09 | val loss  6.37\n",
      "| epoch   0 | [14799/47853] | ms/batch 221.90 | loss  6.26 | val loss  6.42\n",
      "| epoch   0 | [14999/47853] | ms/batch 221.25 | loss  5.92 | val loss  6.41\n",
      "| epoch   0 | [15199/47853] | ms/batch 222.90 | loss  6.28 | val loss  6.41\n",
      "| epoch   0 | [15399/47853] | ms/batch 220.91 | loss  6.61 | val loss  6.38\n",
      "| epoch   0 | [15599/47853] | ms/batch 221.32 | loss  6.30 | val loss  6.39\n",
      "| epoch   0 | [15799/47853] | ms/batch 222.82 | loss  5.95 | val loss  6.39\n",
      "| epoch   0 | [15999/47853] | ms/batch 221.69 | loss  6.06 | val loss  6.39\n",
      "| epoch   0 | [16199/47853] | ms/batch 222.31 | loss  6.39 | val loss  6.39\n",
      "| epoch   0 | [16399/47853] | ms/batch 222.04 | loss  6.10 | val loss  6.38\n",
      "| epoch   0 | [16599/47853] | ms/batch 221.13 | loss  6.28 | val loss  6.42\n",
      "| epoch   0 | [16799/47853] | ms/batch 222.82 | loss  6.36 | val loss  6.41\n",
      "| epoch   0 | [16999/47853] | ms/batch 220.29 | loss  6.06 | val loss  6.43\n",
      "| epoch   0 | [17199/47853] | ms/batch 222.49 | loss  6.49 | val loss  6.41\n",
      "| epoch   0 | [17399/47853] | ms/batch 221.77 | loss  6.36 | val loss  6.36\n",
      "| epoch   0 | [17599/47853] | ms/batch 221.50 | loss  6.25 | val loss  6.38\n",
      "| epoch   0 | [17799/47853] | ms/batch 219.84 | loss  6.27 | val loss  6.39\n",
      "| epoch   0 | [17999/47853] | ms/batch 221.56 | loss  6.15 | val loss  6.43\n",
      "| epoch   0 | [18199/47853] | ms/batch 221.07 | loss  6.46 | val loss  6.44\n",
      "| epoch   0 | [18399/47853] | ms/batch 221.84 | loss  6.15 | val loss  6.41\n",
      "| epoch   0 | [18599/47853] | ms/batch 220.99 | loss  6.09 | val loss  6.43\n",
      "| epoch   0 | [18799/47853] | ms/batch 223.48 | loss  6.30 | val loss  6.43\n",
      "| epoch   0 | [18999/47853] | ms/batch 221.36 | loss  6.42 | val loss  6.43\n",
      "| epoch   0 | [19199/47853] | ms/batch 220.76 | loss  5.82 | val loss  6.46\n",
      "| epoch   0 | [19399/47853] | ms/batch 221.95 | loss  5.98 | val loss  6.43\n",
      "| epoch   0 | [19599/47853] | ms/batch 222.44 | loss  6.76 | val loss  6.44\n",
      "| epoch   0 | [19799/47853] | ms/batch 220.26 | loss  6.53 | val loss  6.46\n",
      "| epoch   0 | [19999/47853] | ms/batch 222.75 | loss  6.47 | val loss  6.47\n",
      "| epoch   0 | [20199/47853] | ms/batch 221.41 | loss  6.39 | val loss  6.46\n",
      "| epoch   0 | [20399/47853] | ms/batch 221.39 | loss  6.55 | val loss  6.42\n",
      "| epoch   0 | [20599/47853] | ms/batch 221.08 | loss  6.34 | val loss  6.43\n",
      "| epoch   0 | [20799/47853] | ms/batch 221.98 | loss  6.15 | val loss  6.45\n",
      "| epoch   0 | [20999/47853] | ms/batch 221.13 | loss  6.35 | val loss  6.48\n",
      "| epoch   0 | [21199/47853] | ms/batch 222.01 | loss  6.04 | val loss  6.47\n",
      "| epoch   0 | [21399/47853] | ms/batch 222.29 | loss  6.36 | val loss  6.44\n",
      "| epoch   0 | [21599/47853] | ms/batch 220.60 | loss  6.38 | val loss  6.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | [21799/47853] | ms/batch 222.39 | loss  6.32 | val loss  6.45\n",
      "| epoch   0 | [21999/47853] | ms/batch 220.21 | loss  6.36 | val loss  6.47\n",
      "| epoch   0 | [22199/47853] | ms/batch 220.65 | loss  6.22 | val loss  6.50\n",
      "| epoch   0 | [22399/47853] | ms/batch 221.04 | loss  6.45 | val loss  6.43\n",
      "| epoch   0 | [22599/47853] | ms/batch 221.80 | loss  6.33 | val loss  6.48\n",
      "| epoch   0 | [22799/47853] | ms/batch 221.40 | loss  6.43 | val loss  6.45\n",
      "| epoch   0 | [22999/47853] | ms/batch 220.76 | loss  6.29 | val loss  6.50\n",
      "| epoch   0 | [23199/47853] | ms/batch 220.18 | loss  6.52 | val loss  6.48\n",
      "| epoch   0 | [23399/47853] | ms/batch 221.55 | loss  6.09 | val loss  6.43\n",
      "| epoch   0 | [23599/47853] | ms/batch 220.06 | loss  6.51 | val loss  6.46\n",
      "| epoch   0 | [23799/47853] | ms/batch 221.38 | loss  6.20 | val loss  6.46\n",
      "| epoch   0 | [23999/47853] | ms/batch 220.30 | loss  6.52 | val loss  6.42\n",
      "| epoch   0 | [24199/47853] | ms/batch 221.55 | loss  6.29 | val loss  6.49\n",
      "| epoch   0 | [24399/47853] | ms/batch 222.33 | loss  6.45 | val loss  6.47\n",
      "| epoch   0 | [24599/47853] | ms/batch 222.57 | loss  6.45 | val loss  6.48\n",
      "| epoch   0 | [24799/47853] | ms/batch 220.65 | loss  6.21 | val loss  6.51\n",
      "| epoch   0 | [24999/47853] | ms/batch 222.84 | loss  5.77 | val loss  6.55\n",
      "| epoch   0 | [25199/47853] | ms/batch 221.68 | loss  6.35 | val loss  6.52\n",
      "| epoch   0 | [25399/47853] | ms/batch 220.75 | loss  6.17 | val loss  6.49\n",
      "| epoch   0 | [25599/47853] | ms/batch 221.76 | loss  6.33 | val loss  6.52\n",
      "| epoch   0 | [25799/47853] | ms/batch 221.84 | loss  6.19 | val loss  6.50\n",
      "| epoch   0 | [25999/47853] | ms/batch 222.46 | loss  6.03 | val loss  6.53\n",
      "| epoch   0 | [26199/47853] | ms/batch 221.88 | loss  6.66 | val loss  6.51\n",
      "| epoch   0 | [26399/47853] | ms/batch 222.42 | loss  6.34 | val loss  6.49\n",
      "| epoch   0 | [26599/47853] | ms/batch 221.06 | loss  6.32 | val loss  6.52\n",
      "| epoch   0 | [26799/47853] | ms/batch 221.12 | loss  6.72 | val loss  6.51\n",
      "| epoch   0 | [26999/47853] | ms/batch 222.25 | loss  6.31 | val loss  6.51\n",
      "| epoch   0 | [27199/47853] | ms/batch 221.88 | loss  6.50 | val loss  6.47\n",
      "| epoch   0 | [27399/47853] | ms/batch 220.47 | loss  6.45 | val loss  6.46\n",
      "| epoch   0 | [27599/47853] | ms/batch 221.20 | loss  6.28 | val loss  6.47\n",
      "| epoch   0 | [27799/47853] | ms/batch 221.13 | loss  6.34 | val loss  6.53\n",
      "| epoch   0 | [27999/47853] | ms/batch 221.16 | loss  6.37 | val loss  6.52\n",
      "| epoch   0 | [28199/47853] | ms/batch 223.45 | loss  6.41 | val loss  6.51\n",
      "| epoch   0 | [28399/47853] | ms/batch 220.32 | loss  6.28 | val loss  6.48\n",
      "| epoch   0 | [28599/47853] | ms/batch 221.18 | loss  6.42 | val loss  6.47\n",
      "| epoch   0 | [28799/47853] | ms/batch 220.95 | loss  5.96 | val loss  6.51\n",
      "| epoch   0 | [28999/47853] | ms/batch 221.38 | loss  6.23 | val loss  6.48\n",
      "| epoch   0 | [29199/47853] | ms/batch 221.77 | loss  6.39 | val loss  6.51\n",
      "| epoch   0 | [29399/47853] | ms/batch 222.37 | loss  6.11 | val loss  6.49\n",
      "| epoch   0 | [29599/47853] | ms/batch 221.66 | loss  6.21 | val loss  6.51\n",
      "| epoch   0 | [29799/47853] | ms/batch 222.02 | loss  5.86 | val loss  6.52\n",
      "| epoch   0 | [29999/47853] | ms/batch 222.28 | loss  6.44 | val loss  6.53\n",
      "| epoch   0 | [30199/47853] | ms/batch 221.58 | loss  6.28 | val loss  6.48\n",
      "| epoch   0 | [30399/47853] | ms/batch 222.14 | loss  6.42 | val loss  6.48\n",
      "| epoch   0 | [30599/47853] | ms/batch 221.64 | loss  6.07 | val loss  6.49\n",
      "| epoch   0 | [30799/47853] | ms/batch 221.83 | loss  6.39 | val loss  6.50\n",
      "| epoch   0 | [30999/47853] | ms/batch 221.77 | loss  6.36 | val loss  6.50\n",
      "| epoch   0 | [31199/47853] | ms/batch 222.27 | loss  6.41 | val loss  6.49\n",
      "| epoch   0 | [31399/47853] | ms/batch 222.28 | loss  6.61 | val loss  6.51\n",
      "| epoch   0 | [31599/47853] | ms/batch 220.65 | loss  6.26 | val loss  6.51\n",
      "| epoch   0 | [31799/47853] | ms/batch 221.26 | loss  6.28 | val loss  6.51\n",
      "| epoch   0 | [31999/47853] | ms/batch 221.92 | loss  6.38 | val loss  6.49\n",
      "| epoch   0 | [32199/47853] | ms/batch 222.30 | loss  6.49 | val loss  6.51\n",
      "| epoch   0 | [32399/47853] | ms/batch 220.86 | loss  6.50 | val loss  6.47\n",
      "| epoch   0 | [32599/47853] | ms/batch 222.07 | loss  6.33 | val loss  6.52\n",
      "| epoch   0 | [32799/47853] | ms/batch 220.97 | loss  6.58 | val loss  6.52\n",
      "| epoch   0 | [32999/47853] | ms/batch 222.12 | loss  6.66 | val loss  6.47\n",
      "| epoch   0 | [33199/47853] | ms/batch 223.53 | loss  6.29 | val loss  6.50\n",
      "| epoch   0 | [33399/47853] | ms/batch 220.86 | loss  6.28 | val loss  6.51\n",
      "| epoch   0 | [33599/47853] | ms/batch 222.03 | loss  5.97 | val loss  6.50\n",
      "| epoch   0 | [33799/47853] | ms/batch 222.36 | loss  6.56 | val loss  6.52\n",
      "| epoch   0 | [33999/47853] | ms/batch 222.14 | loss  6.58 | val loss  6.51\n",
      "| epoch   0 | [34199/47853] | ms/batch 221.57 | loss  6.68 | val loss  6.51\n",
      "| epoch   0 | [34399/47853] | ms/batch 222.92 | loss  6.21 | val loss  6.48\n",
      "| epoch   0 | [34599/47853] | ms/batch 220.48 | loss  6.12 | val loss  6.53\n",
      "| epoch   0 | [34799/47853] | ms/batch 223.56 | loss  6.29 | val loss  6.52\n",
      "| epoch   0 | [34999/47853] | ms/batch 220.34 | loss  6.11 | val loss  6.53\n",
      "| epoch   0 | [35199/47853] | ms/batch 221.41 | loss  6.36 | val loss  6.54\n",
      "| epoch   0 | [35399/47853] | ms/batch 222.32 | loss  6.50 | val loss  6.55\n",
      "| epoch   0 | [35599/47853] | ms/batch 220.45 | loss  6.61 | val loss  6.56\n",
      "| epoch   0 | [35799/47853] | ms/batch 221.72 | loss  6.18 | val loss  6.50\n",
      "| epoch   0 | [35999/47853] | ms/batch 221.02 | loss  5.97 | val loss  6.52\n",
      "| epoch   0 | [36199/47853] | ms/batch 221.63 | loss  6.32 | val loss  6.53\n",
      "| epoch   0 | [36399/47853] | ms/batch 221.80 | loss  6.37 | val loss  6.53\n",
      "| epoch   0 | [36599/47853] | ms/batch 222.19 | loss  6.40 | val loss  6.55\n",
      "| epoch   0 | [36799/47853] | ms/batch 221.81 | loss  6.25 | val loss  6.58\n",
      "| epoch   0 | [36999/47853] | ms/batch 219.68 | loss  6.20 | val loss  6.53\n",
      "| epoch   0 | [37199/47853] | ms/batch 221.36 | loss  6.17 | val loss  6.50\n",
      "| epoch   0 | [37399/47853] | ms/batch 222.41 | loss  6.12 | val loss  6.51\n",
      "| epoch   0 | [37599/47853] | ms/batch 221.32 | loss  6.11 | val loss  6.55\n",
      "| epoch   0 | [37799/47853] | ms/batch 222.37 | loss  6.39 | val loss  6.56\n",
      "| epoch   0 | [37999/47853] | ms/batch 222.55 | loss  6.44 | val loss  6.58\n",
      "| epoch   0 | [38199/47853] | ms/batch 221.78 | loss  6.27 | val loss  6.55\n",
      "| epoch   0 | [38399/47853] | ms/batch 221.26 | loss  6.36 | val loss  6.55\n",
      "| epoch   0 | [38599/47853] | ms/batch 220.87 | loss  6.31 | val loss  6.55\n",
      "| epoch   0 | [38799/47853] | ms/batch 221.82 | loss  6.24 | val loss  6.54\n",
      "| epoch   0 | [38999/47853] | ms/batch 223.16 | loss  6.13 | val loss  6.55\n",
      "| epoch   0 | [39199/47853] | ms/batch 222.08 | loss  6.26 | val loss  6.53\n",
      "| epoch   0 | [39399/47853] | ms/batch 221.54 | loss  6.41 | val loss  6.54\n",
      "| epoch   0 | [39599/47853] | ms/batch 221.20 | loss  6.27 | val loss  6.56\n",
      "| epoch   0 | [39799/47853] | ms/batch 221.04 | loss  6.32 | val loss  6.56\n",
      "| epoch   0 | [39999/47853] | ms/batch 222.30 | loss  6.33 | val loss  6.56\n",
      "| epoch   0 | [40199/47853] | ms/batch 222.47 | loss  6.49 | val loss  6.54\n",
      "| epoch   0 | [40399/47853] | ms/batch 220.91 | loss  6.57 | val loss  6.53\n",
      "| epoch   0 | [40599/47853] | ms/batch 222.10 | loss  6.38 | val loss  6.55\n",
      "| epoch   0 | [40799/47853] | ms/batch 220.98 | loss  6.30 | val loss  6.53\n",
      "| epoch   0 | [40999/47853] | ms/batch 220.74 | loss  6.17 | val loss  6.55\n",
      "| epoch   0 | [41199/47853] | ms/batch 222.72 | loss  6.35 | val loss  6.54\n",
      "| epoch   0 | [41399/47853] | ms/batch 221.84 | loss  6.29 | val loss  6.53\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5e1aab20beba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0minputs_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-94b71d9c648c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_max_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, max_length, stride, truncation_strategy, pad_to_max_length, is_pretokenized, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             )\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0madded_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_added_tokens_encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madded_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m   1306\u001b[0m                 \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m             return list(\n\u001b[0m\u001b[1;32m   1309\u001b[0m                 itertools.chain.from_iterable(\n\u001b[1;32m   1310\u001b[0m                     (\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1309\u001b[0m                 itertools.chain.from_iterable(\n\u001b[1;32m   1310\u001b[0m                     (\n\u001b[0;32m-> 1311\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_added_tokens_encoder\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                     )\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msub_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordpiece_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0mnever_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnever_split\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnever_split\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnever_split\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;31m# This was added on November 1st, 2018 for the multilingual and Chinese\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# models. This is also applied to the English models now, but it doesn't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36m_clean_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0xFFFD\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_is_whitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() \n",
    "    start_time = time.time()\n",
    "    for i, (inputs_ids, attention_mask, y) in enumerate(train_loader):\n",
    "        inputs_ids = inputs_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = step(inputs_ids, attention_mask, y)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "            \n",
    "        if (i + 1) % log_interval == 0:\n",
    "            with torch.no_grad():\n",
    "                x, x_mask, y = next(iter(val_loader))\n",
    "                x = x.to(device)\n",
    "                x_mask = x_mask.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                v_loss = step(x, x_mask, y)\n",
    "                v_loss = v_loss.item()\n",
    "                \n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
    "                  'ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | val loss {:5.2f}'.format(\n",
    "                    epoch, i, len(train_loader),\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    loss.item(), v_loss))\n",
    "                start_time = time.time()\n",
    "                val_loss.append(v_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from rouge_score import scoring\n",
    "\n",
    "class RougeScore:\n",
    "    '''\n",
    "    mostly from https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/evaluation/metrics.py \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, score_keys=None)-> None:\n",
    "        super().__init__()\n",
    "        if score_keys is None:  \n",
    "            self.score_keys = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
    "        \n",
    "        self.scorer = rouge_scorer.RougeScorer(self.score_keys)\n",
    "        self.aggregator = scoring.BootstrapAggregator()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def prepare_summary(summary):\n",
    "            # Make sure the summary is not bytes-type\n",
    "            # Add newlines between sentences so that rougeLsum is computed correctly.\n",
    "            summary = summary.replace(\" . \", \" .\\n\")\n",
    "            return summary\n",
    "    \n",
    "    def __call__(self, target, prediction):\n",
    "        \"\"\"Computes rouge score.''\n",
    "        Args:\n",
    "        targets: string\n",
    "        predictions: string\n",
    "        \"\"\"\n",
    "\n",
    "        target = self.prepare_summary(target)\n",
    "        prediction = self.prepare_summary(prediction)\n",
    "        \n",
    "        self.aggregator.add_scores(self.scorer.score(target=target, prediction=prediction))\n",
    "\n",
    "        return \n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.rouge_list = []\n",
    "\n",
    "    def result(self):\n",
    "        result = self.aggregator.aggregate()\n",
    "        \n",
    "        for key in self.score_keys:\n",
    "            score_text = \"%s = %.2f, 95%% confidence [%.2f, %.2f]\"%(\n",
    "                key,\n",
    "                result[key].mid.fmeasure*100,\n",
    "                result[key].low.fmeasure*100,\n",
    "                result[key].high.fmeasure*100\n",
    "            )\n",
    "            print(score_text)\n",
    "        \n",
    "        return {key: result[key].mid.fmeasure*100 for key in self.score_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 = 13.29, 95% confidence [12.57, 13.93]\n",
      "rouge2 = 0.21, 95% confidence [0.14, 0.30]\n",
      "rougeLsum = 11.68, 95% confidence [11.08, 12.28]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 13.289427538754687,\n",
       " 'rouge2': 0.21045961905902774,\n",
       " 'rougeLsum': 11.683025084899315}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_score = RougeScore()\n",
    "predictions = []\n",
    "for i, (input_ids, attention_mask, y) in enumerate(test_loader):\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    y = y.to(device)\n",
    "        \n",
    "    summaries = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
    "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
    "    for pred_sent, real_sent in zip(pred, real):\n",
    "        rouge_score(pred_sent, real_sent)\n",
    "        predictions.append(str(\"pred sentence: \" + pred_sent + \"\\n\\n real sentence: \" + real_sent))\n",
    "    if i > 40:\n",
    "        break\n",
    "    \n",
    "rouge_score.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "pred sentence: ##93 ;EU Die dess -s - - -s \" \" \" , die der \" \" - \" \"en \" \" sagt dass \" \" der \" der dess \"s \" sagt \" \" . sagt dass die der der der des - - der des \"s der deses \" \"s ist der des . sagt er \" \" sagte dass \" der der \"e \" \" ist . . sagt die der , sei \" \" nicht \" \"\n",
      "\n",
      " real sentence: 0 ; Experten bezweifeln , ob berfllte Flugzeuge Passagiere gefhrden . Die US - Verbraucherberatungsgruppe sagt , dass Mindestabstnde vorgeschrieben werden mssen . Sicherheitstests in Flugzeugen mit mehr Beinfreiheit als von Fluggesellschaften angeboten , werden durchgefhrt .\n",
      "------\n",
      "------\n",
      "pred sentence: ##92 ;EU Die vonnn der vonN - - -n wurden , der der von Polizei , , , und Polizei , . Polizei , und , , . , , in , , die der , , der , und Frau , , von , , \" , , zu , , sie , , sich , , ein , , er , , im von Polizei zu , er zu , sie . Polizei . Polizei zu und , und wurden , , wegen , ,n , , mit Polizei , in zu , die , , es , , dem zu , der zu , es . Polizei wurde , , Polizei , zu . Polizei und , die Polizei , sie zu , undn , sie nicht , , ihn zu\n",
      "\n",
      " real sentence: 1 ; Betrunkener Teenager kletterte in Lwengehege eines Zoos in Westindien : Rahul Kumar , 17 , lief auf Tiere zu und schrie : \" Heute tte ich einen Lwen ! \" Glcklicherweise strzte er in einen Wassergraben , bevor er die Lwen erreichte und wurde gerettet .\n",
      "------\n",
      "------\n",
      "pred sentence: ##93 ;EU Die dess \"s \" \" \"s der \" \" der \" - \" \" sagt .EU Die der dess sagt dass \" \" dess der der deses \" \"e \" \" ist . sagt dass Menschen die der der der \"en der des - - - \" der . .EU \" ist der des \" - der \" der des . sagt die dess . . sagt \" ist , die der \" ist \" \"en \" \" , der \"e der \" sagt \" sagt dass nicht \" sagt , sei \" \"\n",
      "\n",
      " real sentence: 2 ; Nottingham Forest steht kurz vor der Vertragsverlngerung von Dougie Freedman , der im Februar die Nachfolge des ehemaligen Managers Stuart Pearce angetreten hatte und den Club seitdem auf den neunten Tabellenplatz gefhrt hat .\n",
      "------\n",
      "------\n",
      "pred sentence: ##93 ;EU Die dessss - - -s vonns der dess -s der - -ige dess , , , der der der des - - dess der der vons dess desesss des -ss derss , der , der von , , in , , und , , von , der denn der deses dess in USA wurde , , die der der in letzten Jahren , , den der der -en dess von , die den dess im von , in Haus , , . , , \" , , sich \" \" , \" \" \" zu , , er , , es , , zu , er \" , die \" \" in\n",
      "\n",
      " real sentence: 3 ; Fiorentina - Torhter Neto wurde mit Liverpool und Arsenal in Verbindung gebracht . Neto kam 2011 vom brasilianischen Erstligisten Atletico Paranaense zu Fiorentina und wird laut seinem Agenten auch von PSG und spanischen Clubs gesucht .\n",
      "------\n",
      "------\n",
      "pred sentence: ##93 ;EU Die dessss der dess -ss dess der vonss vons der der deses dess desesss , , , der der der von , , die der der - - - dess vonns des -s - -s , der , , von , der den der der , der des - -igens , - - in USA , , und , , in , , . , , den , , im von , die von Polizei , , - , , mit Polizei , undn , ,n , und Polizei , . Polizei , in und , unden , , \" , , zu , , sie , , sich zu , sie \"\n",
      "\n",
      " real sentence: 4 ; Das Interview mit dem Reality - TV - Star , 69 , wird am Freitag , den 24 . April ausgestrahlt , inmitten anhaltender Spekulationen ber seinen Wechsel zu einer Frau und nach seiner Verwicklung in einen tdlichen Autounfall im Februar . Das Interview wird auch einer von Diane Sawyers ersten Fernsehauftritten nach dem pltzlichen Tod ihres Mannes im vergangenen Jahr sein .\n",
      "------\n",
      "------\n",
      "pred sentence: ##93 ;EU Die dessss der dess -s der vons der der des - -ss , , , der , , die der der der von Polizei , , von Polizei wurden , , und , , . , , in , , \" , , zu , , sie , , sich , , ein , , mit , , er , ,n , , den , , im , , eine , der der , der von , , - , , dem , ,e , , Polizei , und Polizei , . Polizei , von , undn , und Frau , , am , , wegen , , vor , , auf Polizei , zu . , und und , der Polizei , der in , der\n",
      "\n",
      " real sentence: 5 ; Riesenschwein fiel in den Swimmingpool seines Hauses in Ringwood , Hampshire . Es bedurfte der Anstrengungen eines Teams von Feuerwehrleuten , um es aus dem Wasser zu ziehen . Auch ein eigensinniges Pferd musste aus einem Swimmingpool in Sussex gerettet werden .\n",
      "------\n",
      "------\n",
      "pred sentence: ##93 ;EU Die desss - - -ss , der der der dess -s dess \" \" \"s \"s der \" \" , der \"en \" \"ens \" , , , der , , \" , \" \" zu \" sagt . sagt dass \" dass \" \" ist \" \" sagt dass nicht \" sagt \" dass die der der \" der \"e \" \"e der \" - \" \" . sagt \" \" sagte dass \" sei \" \" dass nicht dass \" nicht \" \"\n",
      "\n",
      " real sentence: 6 ; In den letzten drei Monaten des Jahres 2014 verbrachte der durchschnittliche Hrer zehn Stunden pro Woche mit Tuning . Das waren 14 % weniger als zehn Jahre zuvor , als die Menschen 11 , 6 Stunden lang einschalteten . Der BBC Trust hat Firmen den Weg geebnet , sich in einem Product - Placement - Experiment in Lifestyleprogramme auf dem World News - Kanal einzukaufen . Zum Beispiel knnten Verlage dafr bezahlen , dass ihre Bcher auf Talking Books rezensiert werden . Der BBC Trust wird das Programm in einem Jahr berprfen .\n",
      "------\n",
      "------\n",
      "pred sentence: ##93 ;EU Die dessss , , , der der der dess , der von , , in , , und , , von , undn , , . , , im , , die , , \" \" \"e \" \" , , zu \" , \" , die der \" \"en \" \" der \"e , , sich \" \" nicht \" , der \" , er \" \" sagte \" \" sagt dass \" \" dass \" , es \" \" ist \" sagt . sagt dass , sei \" \" habe \" \" . Ich , \" ist , sie \" \" die \" \" und \" \"s \" \" zu \" \"\n",
      "\n",
      " real sentence: 7 ; Die Show werde mit einem einstndigen Special zurckkehren , gefolgt von einem Spin - off , sagte Star John Stamos , der die Show am Montagabend auf \" Jimmy Kimmel Live \" ankndigte .\n",
      "------\n",
      "------\n",
      "pred sentence: ##93 ;EU Die dess - - -sss -s -ens der desss dess desesss der vonss , , , der der der von - - dess , der von , , die der der deses dess der der in USA wurde , , von Polizei , , und , , . , , in , , \" , , im von , der , , - , , er , , den , , zu , , sie , , sich zu , sie zu , er \" , er nicht , er zu , die , , ein , er in , er sich zu . , der \" , \" \" , der nicht , , eine \" \" \" zu\n",
      "\n",
      " real sentence: 8 ; Reanne Evans traf in der WM - Qualifikation auf Ken Doherty . Doherty gewann 1997 die Weltmeisterschaft . Evans verlor den ersten Frame 71 - 15 gegen Doherty . Doch der gebrtige Dudley kmpfte sich zurck und fhrte 4 - 3 . Ken Doherty gelang es jedoch , einen packenden Wettkampf mit 10 - 8 zu beenden .\n",
      "------\n",
      "------\n",
      "pred sentence: ##93 ; ;EU Die dess -sss desss der dess desess der vons des -s , , , der der der , , von , , . , , und , , in , , die der , der , von Polizei , , den , , zu , , \" , , ein , , sich , , dem , , er , , im von Polizei \" \" \" , \" \"e \" \" zu \" sagt . Polizei , der Polizei , er \" \" wurde , , sie , , eine , , auf zu , er zu , sie zu , die , er nicht , , es , , das zu , zu . Polizei zu , der zu , \" sagte ,\n",
      "\n",
      " real sentence: 9 ; Wegen sexuellen Missbrauchs von Kindern muss die Bande insgesamt 31 Jahre ins Gefngnis . Die Taten ereigneten sich in Autos , Wldern oder in den Wohnungen der Angeklagten in Banbury . Opfer wurden zu Partys gelockt , die ber soziale Medien organisiert wurden , und dann missbraucht . Mdchen im Alter zwischen 13 und 16 Jahren wurden von der Bande zwischen 2009 und 2014 ausgebeutet .\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for pred in predictions[:10]:\n",
    "    print(\"------\")\n",
    "    print(pred)\n",
    "    print(\"------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"../data/bert_result_german.txt\"\n",
    "for pred in predictions:\n",
    "    with open(result_path, \"a\") as file:\n",
    "        file.write(pred + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textsummary",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
